# -*- coding: utf-8 -*-
"""retrain_sgd_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dMoyajAN7ylxTsAH6yNhV0pNamS_xTtZ

Retraining SGD Classifier
"""

import os
import re
import spacy
from joblib import load, dump
import pkg_resources
import shutil
import pandas as pd
from datetime import datetime

# from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import classification_report

"""### Load NER, Vectorizer and False Positive Detector Models"""

data_path = "copyright_data/"
model_path = "models/"

entity_recognizer = spacy.load(model_path + "entity_recognizer")
vectorizer = load(model_path + "copyrightfpd_tfidf.pkl")
false_positive_detector = load(model_path + "copyrightfpd_sgd.pkl")

"""Load Dataset"""

def monitor_for_new_data():
    files = [f for f in os.listdir(data_path) if f.endswith('.csv')]
    return files

"""### Preprocessing"""

def preprocess_data(data):
    """
    Preprocesses the given data by performing various text cleaning and
    transformation tasks.

    Parameters:
    data (iterable): The data to preprocess.

    Returns:
    data (list): List of preprocessed strings.
    """

    # Ensure the data is a list of strings
    data = ensure_list_of_strings(data)

    # Replace copyright holder entities in the data
    data = replace_entities(data)

    # Perform text substitutions for dates, numbers, symbols, emails, etc.
    data = perform_text_substitutions(data)

    return data

def ensure_list_of_strings(data):
    """
    Ensures the data is a list of strings.

    If the input data is not a list, attempts to convert it to a list.
    Then, ensures each element of the list is a string.

    Parameters:
    data (iterable): The data to be converted to a list of strings.

    Returns:
    list: A list of strings.
    """

    # If data is not a list, try converting it to a list
    if not isinstance(data, list):
        data = data.to_list()
    # Ensure each item in the list is a string
    return [str(item) for item in data]

def replace_entities(data):
    """
    Replaces detected copyright holder entities with ' ENTITY '.

    Uses the entity_recognizer model to identify copyright holder entities,
    which are often name or organization entities, and replaces them with
    the string ' ENTITY '.

    Parameters:
    data (list): A list of strings.

    Returns:
    list: A list of strings with copyright holder entities replaced.
    """

    new_data = []
    for sentence in data:
        # Process the sentence using the entity recognizer
        doc = entity_recognizer(sentence)
        new_sentence = doc.text
        for entity in doc.ents:
            # If the entity is a copyright holder entity, replace it with
            # ' ENTITY '
            if entity.label_ == 'ENT':
                new_sentence = re.sub(re.escape(entity.text), ' ENTITY ',
                                      new_sentence)
        new_data.append(new_sentence)
    return new_data

def perform_text_substitutions(data):
    """
    Performs a series of text substitutions to clean and standardize the
    data.

    This includes:
    - Replacing four-digit numbers (assumed to be years) with ' DATE '.
    - Removing all other numbers.
    - Replacing copyright symbols with ' COPYRIGHTSYMBOL '.
    - Replacing emails with ' EMAIL '.
    - Removing any special characters not already replaced or removed.
    - Converting text to lowercase.
    - Stripping extra whitespace from the text.

    Parameters:
    data (list): A list of strings.

    Returns:
    list: A list of cleaned and standardized strings.
    """

    # Define the substitution patterns and their replacements
    subs = [
        (r'\d{4}', ' DATE '),
        (r'\d+', ' '),
        (r'Â©', ' COPYRIGHTSYMBOL '),
        (r'\(c\)', ' COPYRIGHTSYMBOL '),
        (r'\(C\)', ' COPYRIGHTSYMBOL '),
        (
        r"""(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|"(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21\x23-\x5b\x5d-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])*")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21-\x5a\x53-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])+)\])""",
        ' EMAIL '),
        (r'[^a-zA-Z0-9]', ' ')
    ]
    # Perform the substitutions for each pattern in the list
    for pattern, replacement in subs:
        data = [re.sub(pattern, replacement, sentence) for sentence in data]
    # Convert text to lowercase and strip extra whitespace
    return [sentence.lower().strip() for sentence in data]

"""### Retrain"""

def retrain_and_save_model():
    new_files = monitor_for_new_data()

    if new_files:
        for file in new_files:
            df_new = pd.read_csv(os.path.join(data_path, file))
            new_data = df_new['copyright']
            new_labels = df_new['falsePositive']

    # Preprocess the data before training
    preprocessed_new_data = preprocess_data(new_data)

    # Fit the vectorizer to the preprocessed data
    X_train_vectorized = vectorizer.transform(preprocessed_new_data)

    false_positive_detector.partial_fit(X_train_vectorized, new_labels)


    # Determine new version number
    version = datetime.now().strftime("%Y%m%d%H%M%S")
    model_version_path = model_path + f"copyrightfpd_sgd_v{version}.pkl"

    # Save the updated model
    dump(false_positive_detector, model_version_path)

if __name__ == "__main__":
    retrain_and_save_model()